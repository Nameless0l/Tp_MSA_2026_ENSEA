\documentclass[12pt,a4paper]{article}

% Packages essentiels
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{lastpage}

% Configuration de la page
\geometry{
    top=2.5cm,
    bottom=2.5cm,
    left=2.5cm,
    right=2.5cm,
    headheight=30pt
}

% Couleurs ENSEA
\definecolor{ensearose}{RGB}{200,16,82}
\definecolor{enseagris}{RGB}{100,100,100}

% En-tête et pied de page
\pagestyle{fancy}
\fancyhf{}

% En-tête avec logo
\fancyhead[L]{\includegraphics[height=1.2cm]{logo/logo_ensea.png}}
\fancyhead[R]{\textcolor{enseagris}{\small Modélisation des Signaux Aléatoires - MSA}}

% Pied de page
\fancyfoot[L]{\textcolor{enseagris}{\small MBASSI EWOLO \& ABDOULKADER - 2G3TD1P5}}
\fancyfoot[R]{\textcolor{enseagris}{\small \thepage/\pageref{LastPage} - \today}}

% Lignes de séparation
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.5pt}

% Configuration des liens
\hypersetup{
    colorlinks=true,
    linkcolor=ensearose,
    urlcolor=ensearose,
    citecolor=ensearose
}

%==============================================================================
% DÉBUT DU DOCUMENT
%==============================================================================

\begin{document}

%==============================================================================
% PAGE DE GARDE
%==============================================================================

\begin{titlepage}
    \vspace*{-3.05cm}
    \hspace*{-3.25cm}
    \includegraphics[width=5cm]{logo/gauche-logo.png}
    
    \vspace{4cm}
    
    \centering
    
    % Titre du TP
    {\Huge\bfseries TP Majeure Signal S7\\
Modélisation des Signaux Aléatoires\par}
    \vspace{0.5cm}
    {\LARGE\bfseries Compression de la Parole par Prédiction Linéaire (LPC)\par}
    
    \vfill
    
    % Bande colorée avec auteurs
    \begin{tikzpicture}
        \fill[ensearose] (-8,0) rectangle (8,2);
        \node[white, font=\large, text width=14cm, align=center] at (0,1) {
            \textbf{Réalisé par :}\\
            MBASSI EWOLO Loïc Aron\\
            ABDOULKADER MOHAMED Yacoub
        };
    \end{tikzpicture}
    
    \vspace{1cm}
    
    % Date et groupe
    {\large Groupe : 2G3TD1P5\par}
    \vspace{0.3cm}
    {\large \today\par}
    
\end{titlepage}

% TABLE DES MATIÈRES
\tableofcontents
\newpage

%==============================================================================
% CONTENU DU RAPPORT - Séance 1 :
%==============================================================================

\section{Séance 1 : Estimation de l'Autocorrélation}

\subsection{Génération de Signaux Tests}

Trois signaux artificiels ont été générés pour tester les estimateurs d'autocorrélation :

\begin{itemize}
    \item \textbf{Bruit Blanc Gaussien :} Écart-type $\sigma_b = 2.0$ (N=256 échantillons).
    \begin{equation}
        X[n] \sim \mathcal{N}(0, \sigma_b^2)
    \end{equation}
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.9\linewidth]{figures/bruit_blanc_signal.png}
        \caption{Réalisation d'un bruit blanc gaussien.}
        \label{fig:bruit_blanc_signal}
    \end{figure}
    
    \item \textbf{Processus AR(1) :} Paramètre $a = 0.8$, variance de l'innovation $\sigma_e^2 = 4$.
    \begin{equation}
        X[n] = -a \cdot X[n-1] + B[n], \quad B[n] \sim \mathcal{N}(0, \sigma_e^2)
    \end{equation}
    La variance théorique du processus est $\gamma_X[0] = \frac{\sigma_e^2}{1-a^2} = 11.11$.
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.9\linewidth]{figures/ar1_signal.png}
        \caption{Réalisation d'un processus AR(1) montrant les corrélations temporelles.}
        \label{fig:ar1_signal}
    \end{figure}
    
    \item \textbf{Sinusoïde à Phase Aléatoire :} Fréquence réduite $\nu_0 = 0.1$, amplitude $A = 3.0$.
    \begin{equation}
        X[n] = A \sin(2\pi \nu_0 n + \phi), \quad \phi \sim \mathcal{U}[0, 2\pi)
    \end{equation}
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.9\linewidth]{figures/sinusoide_signal.png}
        \caption{Sinusoïde à phase aléatoire, processus périodique stationnaire.}
        \label{fig:sinusoide_signal}
    \end{figure}
\end{itemize}

Ces trois signaux représentent des cas typiques : bruit blanc (pas de corrélation), AR(1) (corrélation décroissante exponentielle), et sinusoïde (corrélation périodique).

\subsection{Estimateur Biaisé de l'Autocorrélation}

L'estimateur biaisé de l'autocorrélation est défini par :
\begin{equation}
    \hat{\gamma}_{X,b}[p] = \frac{1}{N} \sum_{k=0}^{N-1-|p|} x[k] x[k+|p|]
\end{equation}

\subsubsection{Résultats}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{figures/autocorr_biaisee_tests.png}
    \caption{Estimateur biaisé de l'autocorrélation pour les trois signaux tests.}
    \label{fig:autocorr_biaisee_tests}
\end{figure}

\textbf{Observations :}
\begin{itemize}
    \item \textbf{Bruit Blanc :} L'autocorrélation s'annule rapidement pour $p > 0$, conformément à la théorie ($\gamma[p] = \sigma^2 \delta[p]$).
    \item \textbf{AR(1) :} Décroissance exponentielle observée, cohérente avec $\gamma[p] = \gamma[0] \cdot a^{|p|}$.
    \item \textbf{Sinusoïde :} Structure périodique visible, caractéristique d'un signal sinusoïdal.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/autocorr_biaisee_ar1_theo.png}
    \caption{Comparaison entre l'estimateur biaisé et l'autocorrélation théorique pour un processus AR(1).}
    \label{fig:autocorr_biaisee_ar1_theo}
\end{figure}

L'estimateur biaisé converge bien vers les valeurs théoriques pour le processus AR(1). Le biais se manifeste par une sous-estimation croissante aux grands décalages $p$, due au facteur de normalisation $1/N$ fixe.

\subsection{Estimateur Non-Biaisé de l'Autocorrélation}

L'estimateur non-biaisé de l'autocorrélation est défini par :
\begin{equation}
    \hat{\gamma}_{X,nb}[p] = \frac{1}{N-|p|} \sum_{k=0}^{N-1-|p|} x[k] x[k+|p|]
\end{equation}

\subsubsection{Résultats}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{figures/autocorr_non_biaisee_tests.png}
    \caption{Estimateur non-biaisé de l'autocorrélation pour les trois signaux tests.}
    \label{fig:autocorr_non_biaisee_tests}
\end{figure}

\subsection{Comparaison des Estimateurs}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{figures/autocorr_comparaison_biais.png}
    \caption{Comparaison entre les estimateurs biaisé et non-biaisé pour les trois signaux tests.}
    \label{fig:autocorr_comparaison}
\end{figure}

\textbf{Analyse :}
\begin{itemize}
    \item \textbf{Bruit Blanc :} Les deux estimateurs donnent des résultats similaires. L'estimateur non-biaisé présente une variance légèrement plus élevée aux grands décalages.
    
    \item \textbf{AR(1) :} L'estimateur biaisé suit mieux la courbe théorique aux grands décalages. L'estimateur non-biaisé présente des oscillations importantes quand $p \to N$, dues à la variance qui explose avec le facteur $1/(N-p)$.
    
    \item \textbf{Sinusoïde :} Les deux estimateurs capturent bien la périodicité. L'estimateur non-biaisé montre plus de fluctuations aux grands décalages.
\end{itemize}

\textbf{Conclusion :} Pour les signaux de parole (segments courts, $N=256$), l'estimateur biaisé est préférable car il présente une variance plus faible, critère important pour des fenêtres temporelles courtes.

\subsection{Caractérisation des signaux voisés et non voisés}

\subsubsection{Analyse d'un signal voisé}

Un signal voisé (ex: voyelle) est caractérisé par une structure quasi-périodique due aux vibrations des cordes vocales. Cette périodicité se reflète dans la fonction d'autocorrélation normalisée.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/signal_voise_autocorr.png}
    \caption{Signal voisé et son autocorrélation normalisée. Le second pic indique la pseudo-période $T_0$ (pitch).}
    \label{fig:signal_voise}
\end{figure}

\textbf{Observations :}
\begin{itemize}
    \item Le signal présente une structure répétitive sur la fenêtre temporelle.
    \item L'autocorrélation normalisée présente un second pic marqué (amplitude $> 0.5$) à la position $p = T_0$.
    \item La pseudo-période $T_0$ permet de calculer la fréquence fondamentale (pitch) : $F_0 = 1/T_0$.
\end{itemize}

\subsubsection{Analyse d'un signal non voisé}

Un signal non voisé (ex: consonnes fricatives) est assimilable à du bruit filtré. L'autocorrélation décroît rapidement.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/signal_nonvoise_autocorr.png}
    \caption{Signal non voisé et son autocorrélation normalisée. Absence de structure périodique.}
    \label{fig:signal_nonvoise}
\end{figure}

\textbf{Observations :}
\begin{itemize}
    \item Le signal ressemble à du bruit aléatoire.
    \item L'autocorrélation normalisée décroît rapidement vers zéro (pas de second pic significatif).
    \item Amplitude du second pic $< 0.3$ (typiquement).
\end{itemize}

\subsubsection{Critère de détection : fonction \texttt{isvoiced}}

On utilise l'amplitude du second maximum de l'autocorrélation normalisée comme critère de décision :

\begin{equation}
\text{isvoiced}(X) = 
\begin{cases}
\text{True} & \text{si } \max_{p > 0} \left( \frac{\hat{\gamma}_X[p]}{\hat{\gamma}_X[0]} \right) > \text{seuil} \\
\text{False} & \text{sinon}
\end{cases}
\end{equation}

Le seuil expérimental est fixé à $0.3$ après étude de plusieurs signaux voisés et non voisés.

\textbf{Tests :}
\begin{itemize}
    \item Signal voisé : \texttt{isvoiced} retourne \texttt{True} (\checkmark).
    \item Signal non voisé : \texttt{isvoiced} retourne \texttt{False} (\checkmark).
\end{itemize}

\subsection{Pour aller plus loin : Calcul rapide par FFT}

\subsubsection{Principe théorique}

Le théorème de Wiener-Khintchine établit que la densité spectrale de puissance $S_X(\nu)$ est la transformée de Fourier de l'autocorrélation :

\begin{equation}
S_X(\nu) = \text{TF}\{\gamma_X[p]\}
\end{equation}

Inversement :

\begin{equation}
\gamma_X[p] = \text{TF}^{-1}\{S_X(\nu)\} = \text{TF}^{-1}\{|X(\nu)|^2\}
\end{equation}

où $X(\nu)$ est la transformée de Fourier du signal. Cette relation permet de calculer l'autocorrélation via :

\begin{equation}
\gamma_X[p] = \text{IFFT}\left\{\text{FFT}(x) \cdot \text{FFT}^*(x)\right\} = \text{IFFT}\left\{|\text{FFT}(x)|^2\right\}
\end{equation}

\subsubsection{Complexité algorithmique}

\begin{itemize}
    \item \textbf{Méthode directe :} $\mathcal{O}(N \cdot p_{\text{max}})$ opérations.
    \item \textbf{Méthode FFT :} $\mathcal{O}(N \log N)$ opérations (grâce à l'algorithme de Cooley-Tukey).
\end{itemize}

Pour $N = 256$ et $p_{\text{max}} = 100$, l'accélération attendue est d'un facteur $\approx 10$-$20$.

\subsubsection{Résultats expérimentaux}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\linewidth]{figures/autocorr_fft_comparison.png}
    \caption{Comparaison entre la méthode directe et la méthode FFT. Les deux courbes sont superposées (erreur numérique négligeable).}
    \label{fig:autocorr_fft}
\end{figure}

\textbf{Observations :}
\begin{itemize}
    \item Les deux méthodes produisent des résultats identiques (à la précision machine près).
    \item Le temps de calcul par FFT est réduit d'un facteur $\times 10$ à $\times 20$ selon $N$ et $p_{\text{max}}$.
    \item Cette optimisation est cruciale pour le traitement en temps réel de la parole.
\end{itemize}

\section{Séance 2 : Analyse Spectrale}

\subsection{Estimation de la DSP : Corrélogramme et Périodogramme}

\subsubsection{Principes des deux méthodes}

La densité spectrale de puissance (DSP) d'un processus $X$ peut être estimée par deux approches équivalentes :

\textbf{1. Corrélogramme :} Basé sur le théorème de Wiener-Khintchine :
\begin{equation}
\hat{S}_X^{\text{corr}}(\nu) = \text{TFD}\{\hat{\gamma}_X[p]\}
\end{equation}

où $\hat{\gamma}_X[p]$ est l'estimateur biaisé de l'autocorrélation. L'autocorrélation est symétrisée avant la FFT : $[\hat{\gamma}_X[0], \hat{\gamma}_X[1], \ldots, \hat{\gamma}_X[p_{\max}], \hat{\gamma}_X[p_{\max}-1], \ldots, \hat{\gamma}_X[1]]$.

\textbf{2. Périodogramme :} Calcul direct dans le domaine fréquentiel :
\begin{equation}
\hat{S}_X^{\text{per}}(\nu) = \frac{1}{N} \left| \text{TFD}(x) \right|^2
\end{equation}

où $N$ est le nombre d'échantillons du signal.

\subsubsection{Résultats expérimentaux}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/dsp_comparaison_methodes.png}
    \caption{Comparaison des estimateurs de DSP (corrélogramme vs périodogramme) pour trois types de signaux. Les DSP théoriques sont superposées en noir pointillé.}
    \label{fig:dsp_comparison}
\end{figure}

\textbf{Analyse des résultats :}

\begin{itemize}
    \item \textbf{Bruit Blanc :} DSP théoriquement plate ($S_X(\nu) = \sigma_b^2 = 2.0$). La courbe théorique (ligne noire horizontale) sert de référence. Les deux méthodes donnent des résultats quasi-identiques avec des fluctuations autour de la valeur théorique dues à la variance de l'estimateur. Les estimateurs sont non biaisés asymptotiquement. L'échelle logarithmique permet de mieux observer les fluctuations autour de la valeur moyenne.
    
    \item \textbf{AR(1) :} DSP théorique : $S_X(\nu) = \frac{\sigma_e^2}{|1 - a e^{-j2\pi\nu}|^2}$. La courbe théorique (noire pointillée) montre le comportement passe-bas caractéristique pour $a = 0.8 > 0$. Le corrélogramme et le périodogramme suivent bien la forme attendue et sont très proches de la DSP théorique. Les deux méthodes concordent parfaitement. L'échelle logarithmique révèle une large gamme dynamique ($>20$ dB entre basses et hautes fréquences).
    
    \item \textbf{Sinusoïde :} DSP théorique : deux pics de Dirac en $\pm \nu_0 = \pm 0.1$, mais seul le pic à $+\nu_0$ est visible sur $[0, 0.5]$ (ligne verticale noire). Les deux méthodes montrent un pic à la fréquence théorique $\nu_0 = 0.1$. Le pic est étalé (non infiniment fin) en raison de la résolution fréquentielle limitée par $N = 256$ échantillons (effet de fenêtrage rectangulaire : convolution avec un sinus cardinal dans le domaine fréquentiel). L'échelle logarithmique met en évidence le plancher de bruit numérique en dehors du pic.
\end{itemize}

\textbf{Observations techniques :}
\begin{itemize}
    \item Les fréquences affichées sont restreintes à $[0, 0.5]$ (théorème de Shannon : pas d'information au-delà de $F_e/2$).
    \item La normalisation du périodogramme utilise $N$ (nombre d'échantillons du signal), pas $N_{\text{fft}}$.
    \item Le corrélogramme nécessite $p_{\max} \leq N-1$ pour éviter des valeurs d'autocorrélation non définies.
    \item Les deux méthodes sont équivalentes asymptotiquement (théorème de Wiener-Khintchine).
\end{itemize}

\subsubsection{Moyennage pour réduire la variance (Checkpoint 8)}

Le périodogramme et le corrélogramme sont des estimateurs asymptotiquement non biaisés de la DSP. Cependant, leur variance ne converge pas vers zéro quand $N \to \infty$ (sauf pour des processus totalement prédictibles). Pour des processus aléatoires, la variance reste constante, ce qui rend l'estimation peu fiable.

\textbf{Solution : Moyennage sur $K$ segments}

La méthode consiste à :
\begin{enumerate}
    \item Découper le signal de longueur $N$ en $K$ segments de longueur $N/K$.
    \item Estimer la DSP sur chaque segment.
    \item Moyenner les $K$ estimations.
\end{enumerate}

\textbf{Résultat théorique :} Si les segments sont décorrélés, la variance de l'estimateur moyenné est divisée par $K$ :
\[
\text{Var}[\hat{S}_X^{(K)}(\nu)] = \frac{1}{K} \text{Var}[\hat{S}_X(\nu)]
\]

\textbf{Compromis :} Réduire la variance dégrade la résolution fréquentielle, car les segments sont plus courts :
\[
\Delta \nu = \frac{1}{N/K} = \frac{K}{N}
\]

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/dsp_moyennage_variance.png}
    \caption{Effet du moyennage sur $K$ segments ($N=4096$, $N_{\text{fft}}=512$). Ligne 1 : Bruit blanc. Ligne 2 : AR(1) (échelle log). Ligne 3 : Sinusoïde (échelle log). De gauche à droite : $K \in \{1, 2, 4, 8\}$.}
    \label{fig:dsp_moyennage}
\end{figure}

\textbf{Observations :}

\begin{itemize}
    \item \textbf{Bruit Blanc :} 
    \begin{itemize}
        \item $K=1$ : Fortes fluctuations autour de $\sigma_b^2 = 2.0$.
        \item $K=8$ : Estimation beaucoup plus lisse, proche de la valeur théorique.
        \item La variance mesurée diminue bien d'un facteur proche de $K$ (confirmation expérimentale).
    \end{itemize}
    
    \item \textbf{AR(1) :}
    \begin{itemize}
        \item Le moyennage réduit fortement les fluctuations, notamment aux hautes fréquences.
        \item La forme globale (comportement passe-bas) reste préservée.
        \item Variance réduite selon le facteur $K$ attendu.
    \end{itemize}
    
    \item \textbf{Sinusoïde :}
    \begin{itemize}
        \item $K=1$ : Pic bien localisé à $\nu_0 = 0.1$, mais plancher de bruit fluctuant.
        \item $K$ croissant : Le plancher de bruit devient plus lisse, mais le pic s'élargit (perte de résolution fréquentielle).
        \item Pour $K=8$, le pic est étalé sur plusieurs bins fréquentiels (résolution dégradée : $\Delta \nu = 8/4096 \approx 0.002$ au lieu de $1/4096 \approx 0.00024$).
    \end{itemize}
\end{itemize}

\textbf{Méthodes classiques :}
\begin{itemize}
    \item \textbf{Bartlett :} Segments non chevauchants, fenêtre rectangulaire (implémenté ici).
    \item \textbf{Welch :} Segments chevauchants (typiquement 50\%), fenêtrage (Hann, Hamming) pour réduire les lobes secondaires.
\end{itemize}

\textbf{Conclusion :} Le moyennage est essentiel pour réduire la variance de l'estimation spectrale, mais il induit un compromis variance-résolution. Pour des applications nécessitant une haute résolution fréquentielle (détection de raies spectrales), on privilégiera $K$ faible. Pour une estimation robuste de l'enveloppe spectrale (parole, bruit), on préférera $K$ élevé.

\subsubsection{Fenêtrage temporel (Checkpoint 9)}

Le fenêtrage permet de contrôler les lobes secondaires et la résolution fréquentielle lors de l'estimation spectrale. Une fenêtre temporelle $w[n]$ est appliquée au signal avant calcul de la FFT : $x_w[n] = x[n] \cdot w[n]$.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/dsp_fenetrage.png}
    \caption{Effet de différentes fenêtres sur l'estimation spectrale d'une sinusoïde ($\nu_0 = 0.1$, $N=256$, $N_{\text{fft}}=512$). Ligne 1 : Rectangulaire, Triangulaire, Hann. Ligne 2 : Hamming, Blackman.}
    \label{fig:dsp_fenetrage}
\end{figure}

\textbf{Propriétés des fenêtres testées :}

\begin{itemize}
    \item \textbf{Rectangulaire :} $w[n] = 1$
    \begin{itemize}
        \item Résolution maximale (lobe principal $2/N$).
        \item Lobes secondaires élevés ($-13.3$ dB, pente $-20$ dB/décade).
        \item Convient pour signaux à forte SNR ou quand la résolution est critique.
    \end{itemize}
    
    \item \textbf{Triangulaire (Bartlett) :} $w[n] = 1 - |1 - \frac{2n+1}{N}|$
    \begin{itemize}
        \item Lobe principal $4/N$ (perte de résolution d'un facteur 2).
        \item Lobes secondaires atténués ($-26.5$ dB, pente $-40$ dB/décade).
        \item Compromis résolution/rejection modéré.
    \end{itemize}
    
    \item \textbf{Hann :} $w[n] = \frac{1 - \cos(\frac{2\pi n}{N-1})}{2}$
    \begin{itemize}
        \item Lobe principal $4/N$.
        \item Forte atténuation des lobes ($-31.5$ dB, pente $-60$ dB/décade).
        \item Excellent compromis général, très utilisée en pratique.
    \end{itemize}
    
    \item \textbf{Hamming :} $w[n] = 0.54 - 0.46 \cos(\frac{2\pi n}{N-1})$
    \begin{itemize}
        \item Lobe principal $4/N$.
        \item Lobes secondaires très faibles ($-42.7$ dB), mais pente faible ($-20$ dB/décade).
        \item Optimal pour minimiser le pic du lobe secondaire.
        \item Préférée pour détecter harmoniques proches.
    \end{itemize}
    
    \item \textbf{Blackman :} $w[n] = 0.42 - 0.5 \cos(\frac{2\pi n}{N-1}) + 0.08 \cos(\frac{4\pi n}{N-1})$
    \begin{itemize}
        \item Lobe principal large ($6/N$, perte de résolution d'un facteur 3).
        \item Lobes secondaires très faibles ($-58.1$ dB, pente $-60$ dB/décade).
        \item Meilleure rejection des lobes, au prix de la résolution.
    \end{itemize}
\end{itemize}

\textbf{Observations sur la figure \ref{fig:dsp_fenetrage} :}

\begin{itemize}
    \item La fenêtre rectangulaire produit un pic étroit mais avec des lobes secondaires prononcés (fuite spectrale importante).
    \item Hann, Hamming et Blackman réduisent progressivement les lobes secondaires au prix d'un élargissement du pic principal.
    \item Pour une sinusoïde pure, Blackman donne la meilleure suppression des artefacts hors du pic.
\end{itemize}

\textbf{Critères de choix de fenêtre :}

\begin{itemize}
    \item \textbf{Signaux à raies (sons voisés) :} Hann ou Hamming (bon compromis résolution/rejection). Utiliser Hamming si harmoniques très proches.
    
    \item \textbf{Signaux peu structurés (sons non voisés, bruit) :} Rectangulaire pour maximiser la résolution fréquentielle.
    
    \item \textbf{Mesure d'amplitude d'une harmonique :} Normaliser la fenêtre par $\sum_{n} w[n]$ pour préserver l'amplitude. La hauteur du pic donne alors directement l'amplitude de la composante.
    
    \item \textbf{Mesure de puissance (bruit blanc) :} Normaliser par $\sum_{n} w[n]^2$ pour retrouver la variance correcte dans la DSP estimée.
    
    \item \textbf{Mesure précise de fréquence (pitch) :} Rectangulaire ou Hamming (lobe principal le plus étroit possible).
\end{itemize}

\textbf{Application à la parole :}

\begin{itemize}
    \item \textbf{Sons voisés :} Fenêtre de Hann ou Hamming pour l'analyse harmonique (formants). Permet de séparer les harmoniques proches tout en limitant les interférences entre raies.
    
    \item \textbf{Sons non voisés :} Fenêtre rectangulaire acceptable car le spectre est continu (pas de raies à séparer).
    
    \item \textbf{Détection voisé/non voisé par DSP :} Calculer le rapport énergie dans les basses fréquences / énergie totale. Un son voisé présente des pics marqués (harmoniques), un son non voisé a un spectre plat. Critère similaire à celui basé sur l'autocorrélation (présence d'un pic secondaire), mais moins robuste au bruit.
\end{itemize}

\end{document}